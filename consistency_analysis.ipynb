{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e71d720",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import evaluate\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from utils.task_config import task_config\n",
    "from utils.analysis_helpers import get_table, get_consistency_matrix, load_standardized_response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bec1dbf",
   "metadata": {},
   "source": [
    "# Consistencies PAWS-X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ae07b43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum % of invalid responses 0.75\n"
     ]
    }
   ],
   "source": [
    "task_instruction = [(\"en\", \"en\"), \n",
    "                    (\"en\", \"de_from_en-translation\"), \n",
    "                    (\"de_from_en-translation\", \"en\"),\n",
    "                    (\"de_from_en-translation\", \"de_from_en-translation\")]\n",
    "consistencies = get_consistency_matrix(task_instruction, \"individual_tasks\", \"paws-x\")\n",
    "consistencies_df = pd.DataFrame(data=consistencies)\n",
    "table = get_table(consistencies_df).sort_values(by=\"en / en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2415ad88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task/prompt_1\n",
      "de_from_en-translation / de_from_en-translation    0.8355\n",
      "de_from_en-translation / en                        0.8525\n",
      "en / de_from_en-translation                        0.9305\n",
      "en / en                                            1.0000\n",
      "Name: en / en, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(table[\"en / en\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b154400",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum % of invalid responses 0.15\n"
     ]
    }
   ],
   "source": [
    "task_instruction = [(\"en\", \"en\"), \n",
    "                    (\"en\", \"zh_from_en-translation\"), \n",
    "                    (\"zh_from_en-translation\", \"en\"),\n",
    "                    (\"zh_from_en-translation\", \"zh_from_en-translation\")]\n",
    "consistencies = get_consistency_matrix(task_instruction, \"individual_tasks\", \"paws-x\")\n",
    "consistencies_df = pd.DataFrame(data=consistencies)\n",
    "table = get_table(consistencies_df).sort_values(by=\"en / en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22599ba0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task/prompt_1\n",
      "zh_from_en-translation / zh_from_en-translation    0.7600\n",
      "zh_from_en-translation / en                        0.7910\n",
      "en / zh_from_en-translation                        0.9085\n",
      "en / en                                            1.0000\n",
      "Name: en / en, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(table[\"en / en\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dcb8096c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum % of invalid responses 0.8999999999999999\n"
     ]
    }
   ],
   "source": [
    "task_instruction = [(\"de\", \"de\"), \n",
    "                    (\"de\", \"en_from_de-translation\"), \n",
    "                    (\"en_from_de-translation\", \"de\"),\n",
    "                    (\"en_from_de-translation\", \"en_from_de-translation\")]\n",
    "consistencies = get_consistency_matrix(task_instruction, \"individual_tasks\", \"paws-x\")\n",
    "consistencies_df = pd.DataFrame(data=consistencies)\n",
    "table = get_table(consistencies_df).sort_values(by=\"de / de\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a8b54b02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task/prompt_1\n",
      "en_from_de-translation / en_from_de-translation    0.8595\n",
      "en_from_de-translation / de                        0.8645\n",
      "de / en_from_de-translation                        0.9325\n",
      "de / de                                            1.0000\n",
      "Name: de / de, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(table[\"de / de\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b3e9eaa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum % of invalid responses 0.25\n"
     ]
    }
   ],
   "source": [
    "task_instruction = [(\"zh\", \"zh\"), \n",
    "                    (\"zh\", \"en_from_zh-translation\"), \n",
    "                    (\"en_from_zh-translation\", \"zh\"),\n",
    "                    (\"en_from_zh-translation\", \"en_from_zh-translation\")]\n",
    "consistencies = get_consistency_matrix(task_instruction, \"individual_tasks\", \"paws-x\")\n",
    "consistencies_df = pd.DataFrame(data=consistencies)\n",
    "table = get_table(consistencies_df).sort_values(by=\"zh / zh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f9180a7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task/prompt_1\n",
      "en_from_zh-translation / en_from_zh-translation    0.6995\n",
      "en_from_zh-translation / zh                        0.7500\n",
      "zh / en_from_zh-translation                        0.8695\n",
      "zh / zh                                            1.0000\n",
      "Name: zh / zh, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(table[\"zh / zh\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "84359b45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum % of invalid responses 0.5499999999999999\n"
     ]
    }
   ],
   "source": [
    "task_instruction = [(\"en\", \"en\"), \n",
    "                    (\"en\", \"de\"), \n",
    "                    (\"de\", \"en\"),\n",
    "                    (\"de\", \"de\"),\n",
    "                    (\"en\", \"zh\"),\n",
    "                    (\"zh\", \"en\"),\n",
    "                    (\"zh\", \"zh\")]\n",
    "consistencies_pawsx = get_consistency_matrix(task_instruction, \"individual_tasks\", \"paws-x\")\n",
    "consistencies_pawsx_df = pd.DataFrame(data=consistencies_pawsx)\n",
    "table = get_table(consistencies_pawsx_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3a7c785b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task/prompt_1\n",
      "de / de    0.7965\n",
      "de / en    0.8080\n",
      "en / de    0.9255\n",
      "en / en    1.0000\n",
      "en / zh    0.8320\n",
      "zh / en    0.7405\n",
      "zh / zh    0.7090\n",
      "Name: en / en, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "table = get_table(consistencies_pawsx_df)\n",
    "print(table.sort_index()[\"en / en\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "997ff78e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task/prompt_1\n",
      "de / de    1.0000\n",
      "de / en    0.9220\n",
      "en / de    0.8170\n",
      "en / en    0.7965\n",
      "en / zh    0.8110\n",
      "zh / en    0.7430\n",
      "zh / zh    0.7355\n",
      "Name: de / de, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "table = get_table(consistencies_pawsx_df)\n",
    "print(table.sort_index()[\"de / de\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dc4ae359",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task/prompt_1\n",
      "de / de    0.7355\n",
      "de / en    0.7185\n",
      "en / de    0.7365\n",
      "en / en    0.7090\n",
      "en / zh    0.8000\n",
      "zh / en    0.8335\n",
      "zh / zh    1.0000\n",
      "Name: zh / zh, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "table = get_table(consistencies_pawsx_df)\n",
    "print(table.sort_index()[\"zh / zh\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7ecb1b0",
   "metadata": {},
   "source": [
    "# Consistencies XNLI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a7c33e91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum % of invalid responses 0\n"
     ]
    }
   ],
   "source": [
    "task_instruction = [(\"en\", \"en\"), \n",
    "                    (\"en\", \"de_from_en-translation\"), \n",
    "                    (\"de_from_en-translation\", \"en\"),\n",
    "                    (\"de_from_en-translation\", \"de_from_en-translation\")]\n",
    "consistencies = get_consistency_matrix(task_instruction, \"xglue\", \"xnli\")\n",
    "consistencies_df = pd.DataFrame(data=consistencies)\n",
    "table = get_table(consistencies_df).sort_values(by=\"en / en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "450c7852",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task/prompt_1\n",
      "de_from_en-translation / de_from_en-translation    0.734930\n",
      "de_from_en-translation / en                        0.761078\n",
      "en / de_from_en-translation                        0.813373\n",
      "en / en                                            1.000000\n",
      "Name: en / en, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(table[\"en / en\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "542e15a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum % of invalid responses 0\n"
     ]
    }
   ],
   "source": [
    "task_instruction = [(\"en\", \"en\"), \n",
    "                    (\"en\", \"zh_from_en-translation\"), \n",
    "                    (\"zh_from_en-translation\", \"en\"),\n",
    "                    (\"zh_from_en-translation\", \"zh_from_en-translation\")]\n",
    "consistencies = get_consistency_matrix(task_instruction, \"xglue\", \"xnli\")\n",
    "consistencies_df = pd.DataFrame(data=consistencies)\n",
    "table = get_table(consistencies_df).sort_values(by=\"en / en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e1aaa9b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task/prompt_1\n",
      "zh_from_en-translation / zh_from_en-translation    0.669062\n",
      "zh_from_en-translation / en                        0.714770\n",
      "en / zh_from_en-translation                        0.767465\n",
      "en / en                                            1.000000\n",
      "Name: en / en, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(table[\"en / en\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "31443a03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum % of invalid responses 0.059880239520958084\n"
     ]
    }
   ],
   "source": [
    "task_instruction = [(\"de\", \"de\"), \n",
    "                    (\"de\", \"en_from_de-translation\"), \n",
    "                    (\"en_from_de-translation\", \"de\"),\n",
    "                    (\"en_from_de-translation\", \"en_from_de-translation\")]\n",
    "consistencies = get_consistency_matrix(task_instruction, \"xglue\", \"xnli\")\n",
    "consistencies_df = pd.DataFrame(data=consistencies)\n",
    "table = get_table(consistencies_df).sort_values(by=\"de / de\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "07e34e11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task/prompt_1\n",
      "en_from_de-translation / en_from_de-translation    0.633134\n",
      "de / en_from_de-translation                        0.694810\n",
      "en_from_de-translation / de                        0.805589\n",
      "de / de                                            1.000000\n",
      "Name: de / de, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(table[\"de / de\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8ca160df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum % of invalid responses 0.01996007984031936\n"
     ]
    }
   ],
   "source": [
    "task_instruction = [(\"zh\", \"zh\"), \n",
    "                    (\"zh\", \"en_from_zh-translation\"), \n",
    "                    (\"en_from_zh-translation\", \"zh\"),\n",
    "                    (\"en_from_zh-translation\", \"en_from_zh-translation\")]\n",
    "consistencies = get_consistency_matrix(task_instruction, \"xglue\", \"xnli\")\n",
    "consistencies_df = pd.DataFrame(data=consistencies)\n",
    "table = get_table(consistencies_df).sort_values(by=\"zh / zh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dbed397c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task/prompt_1\n",
      "en_from_zh-translation / en_from_zh-translation    0.666068\n",
      "en_from_zh-translation / zh                        0.719760\n",
      "zh / en_from_zh-translation                        0.786826\n",
      "zh / zh                                            1.000000\n",
      "Name: zh / zh, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(table[\"zh / zh\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2bba9802",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum % of invalid responses 0.059880239520958084\n"
     ]
    }
   ],
   "source": [
    "task_instruction = [(\"en\", \"en\"), \n",
    "                    (\"en\", \"de\"), \n",
    "                    (\"de\", \"en\"),\n",
    "                    (\"de\", \"de\"),\n",
    "                    (\"en\", \"zh\"),\n",
    "                    (\"zh\", \"en\"),\n",
    "                    (\"zh\", \"zh\")]\n",
    "consistencies_xnli = get_consistency_matrix(task_instruction, \"xglue\", \"xnli\")\n",
    "consistencies_xnli_df = pd.DataFrame(data=consistencies_xnli)\n",
    "table = get_table(consistencies_xnli_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "475ee822",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task/prompt_1\n",
      "de / de    0.610778\n",
      "de / en    0.723952\n",
      "en / de    0.690020\n",
      "en / en    1.000000\n",
      "en / zh    0.762475\n",
      "zh / en    0.651697\n",
      "zh / zh    0.651098\n",
      "Name: en / en, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "table = get_table(consistencies_xnli_df)\n",
    "print(table[\"en / en\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e096590a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task/prompt_1\n",
      "de / de    1.000000\n",
      "de / en    0.650100\n",
      "en / de    0.789222\n",
      "en / en    0.610778\n",
      "en / zh    0.646707\n",
      "zh / en    0.585828\n",
      "zh / zh    0.587226\n",
      "Name: de / de, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "table = get_table(consistencies_xnli_df)\n",
    "print(table[\"de / de\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1de4109f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task/prompt_1\n",
      "de / de    0.587226\n",
      "de / en    0.612974\n",
      "en / de    0.617764\n",
      "en / en    0.651098\n",
      "en / zh    0.695210\n",
      "zh / en    0.731138\n",
      "zh / zh    1.000000\n",
      "Name: zh / zh, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "table = get_table(consistencies_xnli_df)\n",
    "print(table[\"zh / zh\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fa7ac32",
   "metadata": {},
   "source": [
    "# Consistencies BOOLQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93e08941",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum % of invalid responses 1.9877675840978593\n"
     ]
    }
   ],
   "source": [
    "task_instruction = [(\"en\", \"en\"), \n",
    "                    (\"de_from_en-translation\", \"de_from_en-translation\"),\n",
    "                    (\"zh_from_en-translation\", \"zh_from_en-translation\")\n",
    "                   ]\n",
    "consistencies = get_consistency_matrix(task_instruction, \"super_glue\", \"boolq\")\n",
    "consistencies_df = pd.DataFrame(data=consistencies)\n",
    "table = get_table(consistencies_df).sort_values(by=\"en / en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7549ce59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task/prompt_1\n",
      "zh_from_en-translation / zh_from_en-translation    0.806116\n",
      "de_from_en-translation / de_from_en-translation    0.892966\n",
      "en / en                                            1.000000\n",
      "Name: en / en, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(table[\"en / en\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c553aa7d",
   "metadata": {},
   "source": [
    "# Relation between consistency / translation quality / correctness"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b21d1525",
   "metadata": {},
   "source": [
    "## Evaluations on translations of the input sentences with English instruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d932f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import load_task\n",
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64d3d72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_task_translation_dict():\n",
    "    \n",
    "    init = {\n",
    "        \"paws-x\": {\"de_from_en\": [], \"zh_from_en\": [], \"en_from_de\": [], \"en_from_zh\": []}, \n",
    "        \"xnli\": {\"de_from_en\": [], \"zh_from_en\": [], \"en_from_de\": [], \"en_from_zh\": []}\n",
    "    }\n",
    "    return init\n",
    "\n",
    "def init_task_language_dict():\n",
    "    \n",
    "    init = {\"paws-x\": {\"en\": [], \"de\": [], \"zh\": []}, \"xnli\": {\"en\": [], \"de\": [], \"zh\": []}}\n",
    "    return init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "81b2af7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels_source = init_task_language_dict()\n",
    "predictions_eval_source = init_task_language_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb5a9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for collection, subtask in [(\"individual_tasks\", \"paws-x\"), (\"xglue\", \"xnli\")]:\n",
    "    \n",
    "    for language in [\"en\", \"de\", \"zh\"]:\n",
    "    \n",
    "        test_data = load_task.load_test_split(collection, subtask, language)\n",
    "        labels = test_data[\"label\"]\n",
    "        label_map = task_config[collection][subtask][\"label_map\"][language]\n",
    "        label_map[-1] = -1 \n",
    "        \n",
    "        responses = load_standardized_response(collection, subtask, language, language, temperature=0.25)\n",
    "        predicted_labels = [label_map[r] for r in responses] \n",
    "        predicted_labels_source[subtask][language] = predicted_labels\n",
    "        predictions_eval_source[subtask][language] = [int(predicted_labels[i] == labels[i]) for i in range(len(labels))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f757a343",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels_trans = init_task_translation_dict()\n",
    "predictions_eval_trans = init_task_translation_dict()\n",
    "comet = init_task_translation_dict()\n",
    "bleu = init_task_translation_dict()\n",
    "\n",
    "\n",
    "for collection, subtask in [(\"individual_tasks\", \"paws-x\"), (\"xglue\", \"xnli\")]:\n",
    "    \n",
    "    trans_path = \"translations_gpt-turbo-0301/task/\" + collection + \"/\" + subtask + \"/temp-0.25_topp-1.0_maxt-2048/\"\n",
    "    sentence_keys = task_config[collection][subtask][\"sentence_keys\"]\n",
    "    \n",
    "    for language in [\"de_from_en\", \"zh_from_en\", \"en_from_de\", \"en_from_zh\"]:\n",
    "        \n",
    "        source_language = language[-2:]\n",
    "        target_language = language[0:2]\n",
    "        \n",
    "        test_data_source = load_task.load_test_split(collection, subtask, source_language)\n",
    "        test_data_target = load_task.load_test_split(collection, subtask, target_language)\n",
    "        label_map = task_config[collection][subtask][\"label_map\"][source_language]\n",
    "        labels = test_data_source[\"label\"]        \n",
    "        \n",
    "        # get comet scores\n",
    "        with open (trans_path + language + \"/translation_scores.pkl\", \"rb\") as f: \n",
    "            translation_scores = pickle.load(f)\n",
    "        comet[subtask][language] = translation_scores[\"comet_all\"][0]\n",
    "        \n",
    "        # calculate bleu per sentence: done once, results stored and loaded below\n",
    "        \n",
    "        # data_path = (\n",
    "        #     \"translations_gpt-turbo-0301/task/\" + str(collection) + \"/\" + str(subtask) + \"/\" +\n",
    "        #     \"temp-0.25_topp-1.0_maxt-2048/\" + language + \"/\"\n",
    "        # )\n",
    "        # print(\"Use translated inputs: \", data_path)\n",
    "        # with open(data_path + \"dataset.pkl\", \"rb\") as f:\n",
    "        #     test_data_translation = pickle.load(f)\n",
    "        # \n",
    "        # mt = []\n",
    "        # references = []\n",
    "        # for key in sentence_keys: \n",
    "        #     references += test_data_target[key]\n",
    "        #     mt += test_data_translation[key]\n",
    "        #     \n",
    "        # bleu_metric = evaluate.load(\"sacrebleu\")\n",
    "        # if target_language == \"zh\":\n",
    "        #     tokenize = \"zh\"\n",
    "        # else:\n",
    "        #     tokenize = \"13a\"\n",
    "        # \n",
    "        # for i in tqdm(range(len(mt))):\n",
    "        #     score = bleu_metric.compute(predictions=[mt[i]], references=[references[i]], tokenize=tokenize)\n",
    "        #     bleu[subtask][language].append(score[\"score\"])\n",
    "        \n",
    "        responses = load_standardized_response(collection, \n",
    "                                               subtask, \n",
    "                                               language + \"-translation\", \n",
    "                                               source_language, \n",
    "                                               temperature=0.25)\n",
    "        \n",
    "        predictions = [label_map[response] for response in responses]\n",
    "        predicted_labels_trans[subtask][language] = predictions\n",
    "        predictions_eval = [int(predictions[i] == labels[i]) for i in range(len(labels))]\n",
    "        predictions_eval_trans[subtask][language] = predictions_eval\n",
    "\n",
    "# load calculated bleu scores instead of calculating every time (commented part above)\n",
    "with open(\"translations_gpt-turbo-0301/all_bleu_scores.pkl\", \"rb\") as f: \n",
    "    pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "03f22ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlations = {}\n",
    "consistency_thresholded = {}\n",
    "\n",
    "for subtask in [\"paws-x\", \"xnli\"]:\n",
    "    \n",
    "    correlations[subtask] = {\"de_from_en\": {}, \"zh_from_en\": {}, \"en_from_de\": {}, \"en_from_zh\": {}}\n",
    "    consistency_thresholded[subtask] = {\"de_from_en\": {}, \"zh_from_en\": {}, \"en_from_de\": {}, \"en_from_zh\": {}}\n",
    "    \n",
    "    for language in [\"de_from_en\", \"zh_from_en\", \"en_from_de\", \"en_from_zh\"]:\n",
    "        \n",
    "        pred_source = predicted_labels_source[subtask][language[-2:]]\n",
    "        eval_source = predictions_eval_source[subtask][language[-2:]]\n",
    "        n = len(pred_source)\n",
    "\n",
    "        # average scores for input sentence 1 and input sentence 2\n",
    "        bleu_all = np.array(bleu[subtask][language])\n",
    "        bleu_mean = (bleu_all[0:n] + bleu_all[n:n*2]) / 2\n",
    "        trans_scores = bleu_mean\n",
    "        \n",
    "        pred_trans = predicted_labels_trans[subtask][language]\n",
    "        eval_trans = predictions_eval_trans[subtask][language]\n",
    "        consistency = [int(pred_source[i] == pred_trans[i]) for i in range(n)]\n",
    "        \n",
    "        threshold = 50\n",
    "        \n",
    "        consistency_subset = np.array(consistency)[trans_scores > threshold]\n",
    "        consistency_thresholded[subtask][language][\"consistency\"] = np.mean(consistency_subset).round(3)\n",
    "        consistency_thresholded[subtask][language][\"percent\"] = round(len(consistency_subset) / len(consistency), 3) \n",
    "\n",
    "        corr1 = np.corrcoef(consistency, trans_scores)\n",
    "        corr2 = np.corrcoef(eval_trans, trans_scores)\n",
    "        correlations[subtask][language][\"translations_consistency\"] = [corr1[0,1].round(3)]\n",
    "        correlations[subtask][language][\"translations_performance\"] = [corr2[0,1].round(3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "819bf5b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- paws-x ---\n",
      "                         de_from_en zh_from_en en_from_de en_from_zh\n",
      "translations_consistency    [0.024]    [0.067]    [0.064]    [0.027]\n",
      "translations_performance    [0.084]    [0.071]    [0.068]    [0.044]\n",
      "\n",
      "--- xnli ---\n",
      "                         de_from_en zh_from_en en_from_de en_from_zh\n",
      "translations_consistency    [0.025]     [0.02]    [0.048]    [0.085]\n",
      "translations_performance    [0.007]    [0.017]     [0.03]    [0.045]\n"
     ]
    }
   ],
   "source": [
    "print(\"--- paws-x ---\")\n",
    "print(pd.DataFrame(correlations[\"paws-x\"]))\n",
    "print(\"\\n--- xnli ---\")\n",
    "print(pd.DataFrame(correlations[\"xnli\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e7ab01cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- paws-x ---\n",
      "             de_from_en  zh_from_en  en_from_de  en_from_zh\n",
      "consistency       0.859       0.818       0.871       0.779\n",
      "percent           0.566       0.401       0.671       0.206\n",
      "\n",
      "--- xnli ---\n",
      "             de_from_en  zh_from_en  en_from_de  en_from_zh\n",
      "consistency       0.773       0.717       0.823       0.800\n",
      "percent           0.356       0.323       0.396       0.105\n"
     ]
    }
   ],
   "source": [
    "print(\"--- paws-x ---\")\n",
    "print(pd.DataFrame(consistency_thresholded[\"paws-x\"]))\n",
    "print(\"\\n--- xnli ---\")\n",
    "print(pd.DataFrame(consistency_thresholded[\"xnli\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ceaa42f",
   "metadata": {},
   "source": [
    "# Percentages on complete translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "80660126",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_complete = init_task_translation_dict()\n",
    "predictions_eval_complete = init_task_translation_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c68fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "for collection, subtask in [(\"individual_tasks\", \"paws-x\"), (\"xglue\", \"xnli\")]:\n",
    "   \n",
    "    for language in [\"en-2nd-run\", \"de_from_en\", \"zh_from_en\", \"en_from_de\", \"en_from_zh\"]:\n",
    "        \n",
    "        if language != \"en-2nd-run\":\n",
    "            source_language = language[-2:]\n",
    "            label_map_key = language + \"-translation\"\n",
    "        else: \n",
    "            source_language = \"en\"\n",
    "            label_map_key = \"en\"\n",
    "        test_data_source = load_task.load_test_split(collection, subtask, source_language)\n",
    "        label_map = task_config[collection][subtask][\"label_map\"][label_map_key]\n",
    "        label_map[-1] = -1\n",
    "        labels = test_data_source[\"label\"]\n",
    "        \n",
    "        if language != \"en-2nd-run\": \n",
    "            responses = load_standardized_response(collection,\n",
    "                                                  subtask,\n",
    "                                                  language + \"-translation\", \n",
    "                                                  language + \"-translation\", \n",
    "                                                  temperature=0.25)\n",
    "        else: \n",
    "            responses = load_standardized_response(collection, \n",
    "                                                  subtask, \n",
    "                                                  language, \n",
    "                                                  \"en\", \n",
    "                                                  temperature=.25)\n",
    "        \n",
    "        predictions = [label_map[response] for response in responses]\n",
    "        predictions_complete[subtask][language] = predictions\n",
    "        predictions_eval = [int(predictions[i] == labels[i]) for i in range(len(labels))]\n",
    "        predictions_eval_complete[subtask][language] = predictions_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f034d6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "percentages_complete = {}\n",
    "\n",
    "for subtask in [\"paws-x\", \"xnli\"]:\n",
    "    \n",
    "    percentages_complete[subtask] = {\n",
    "        \"en-2nd-run\": {\"consistent\": {}, #\"consistent_correct\": {}, \"consistent_false\": {}, \n",
    "                       \"fraction_of_correct\": {}, \"fraction_of_false\": {}},\n",
    "        \"de_from_en\": {\"consistent\": {}, #\"consistent_correct\": {}, \"consistent_false\": {}, \n",
    "                       \"fraction_of_correct\": {}, \"fraction_of_false\": {}},\n",
    "        \"zh_from_en\": {\"consistent\": {}, #\"consistent_correct\": {}, \"consistent_false\": {}, \n",
    "                       \"fraction_of_correct\": {}, \"fraction_of_false\": {}},\n",
    "        \"en_from_de\": {\"consistent\": {}, #\"consistent_correct\": {}, \"consistent_false\": {}, \n",
    "                       \"fraction_of_correct\": {}, \"fraction_of_false\": {}},\n",
    "        \"en_from_zh\": {\"consistent\": {}, #\"consistent_correct\": {}, \"consistent_false\": {}, \n",
    "                       \"fraction_of_correct\": {}, \"fraction_of_false\": {}}}\n",
    "    \n",
    "    for language in [\"en-2nd-run\", \"de_from_en\", \"zh_from_en\", \"en_from_de\", \"en_from_zh\"]:\n",
    "        \n",
    "        if language != \"en-2nd-run\": \n",
    "            pred_source = predicted_labels_source[subtask][language[-2:]]\n",
    "            eval_source = predictions_eval_source[subtask][language[-2:]]\n",
    "        else: \n",
    "            pred_source = predicted_labels_source[subtask][\"en\"]\n",
    "            eval_source = predictions_eval_source[subtask][\"en\"]\n",
    "        \n",
    "        n = len(pred_source)\n",
    "        \n",
    "        pred_trans = predictions_complete[subtask][language]\n",
    "        eval_trans = predictions_eval_complete[subtask][language]\n",
    "        consistency = [int(pred_source[i] == pred_trans[i]) for i in range(n)]\n",
    "        \n",
    "        correct_and_consistent = [int(consistency[i] == 1 and eval_source[i] == 1) for i in range(n)]\n",
    "        false_and_consistent = [int(consistency[i] == 1 and eval_source[i] == 0) for i in range(n)]\n",
    "        correct_and_inconsistent = [int(consistency[i] == 0 and eval_source[i] == 1) for i in range(n)]\n",
    "        false_and_inconsistent = [int(consistency[i] == 0 and eval_source[i] == 0) for i in range(n)]\n",
    "        \n",
    "        false = np.sum([eval_source[i] == 0 for i in range(n)])\n",
    "        correct = np.sum([eval_source[i] == 1 for i in range(n)])\n",
    "        percentages_complete[subtask][language][\"fraction_of_false\"] = (np.sum(false_and_consistent) / false).round(3)\n",
    "        percentages_complete[subtask][language][\"fraction_of_correct\"] = (np.sum(correct_and_consistent) /correct).round(3)\n",
    "        percentages_complete[subtask][language][\"consistent\"] = np.mean(consistency).round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fa578c68",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- paws-x --- \n",
      "\n",
      "{'consistent': 0.986, 'fraction_of_correct': 0.99, 'fraction_of_false': 0.977}\n",
      "{'consistent': 0.836, 'fraction_of_correct': 0.887, 'fraction_of_false': 0.667}\n",
      "{'consistent': 0.76, 'fraction_of_correct': 0.776, 'fraction_of_false': 0.708}\n",
      "{'consistent': 0.86, 'fraction_of_correct': 0.917, 'fraction_of_false': 0.721}\n",
      "{'consistent': 0.7, 'fraction_of_correct': 0.817, 'fraction_of_false': 0.524}\n",
      "--- xnli --- \n",
      "\n",
      "{'consistent': 0.979, 'fraction_of_correct': 0.988, 'fraction_of_false': 0.958}\n",
      "{'consistent': 0.735, 'fraction_of_correct': 0.765, 'fraction_of_false': 0.663}\n",
      "{'consistent': 0.669, 'fraction_of_correct': 0.711, 'fraction_of_false': 0.569}\n",
      "{'consistent': 0.633, 'fraction_of_correct': 0.829, 'fraction_of_false': 0.452}\n",
      "{'consistent': 0.666, 'fraction_of_correct': 0.795, 'fraction_of_false': 0.501}\n"
     ]
    }
   ],
   "source": [
    "print(\"--- paws-x --- \\n\")\n",
    "print(percentages_complete[\"paws-x\"][\"en-2nd-run\"])\n",
    "print(percentages_complete[\"paws-x\"][\"de_from_en\"])\n",
    "print(percentages_complete[\"paws-x\"][\"zh_from_en\"])\n",
    "print(percentages_complete[\"paws-x\"][\"en_from_de\"])\n",
    "print(percentages_complete[\"paws-x\"][\"en_from_zh\"])\n",
    "print(\"--- xnli --- \\n\")\n",
    "print(percentages_complete[\"xnli\"][\"en-2nd-run\"]) \n",
    "print(percentages_complete[\"xnli\"][\"de_from_en\"]) \n",
    "print(percentages_complete[\"xnli\"][\"zh_from_en\"]) \n",
    "print(percentages_complete[\"xnli\"][\"en_from_de\"])\n",
    "print(percentages_complete[\"xnli\"][\"en_from_zh\"]) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e36aec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
